[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Crop_yield_CW",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "data/precipitation/readme.html",
    "href": "data/precipitation/readme.html",
    "title": "Annual precipitation - Data package",
    "section": "",
    "text": "This data package contains the data that powers the chart “Annual precipitation” on the Our World in Data website. It was downloaded on May 03, 2025.\n\n\nA filtered subset of the full data was downloaded. The following filters were applied:\n\n\n\nThe high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward.\n\n\n\nThe .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc..\n\n\n\nOur World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source.\n\n\n\n\n\n\nTotal annual precipitation—rain and snow—calculated as the sum of daily averages, reported as the depth of water falling to Earth’s surface, excluding fog and dew. Last updated: January 7, 2025\nNext update: July 2025\nDate range: 1940–2024\nUnit: millimeters\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nContains modified Copernicus Climate Change Service information (2025) – with major processing by Our World in Data\n\n\n\nContains modified Copernicus Climate Change Service information (2025) – with major processing by Our World in Data. “Annual precipitation” [dataset]. Contains modified Copernicus Climate Change Service information, “ERA5 monthly averaged data on single levels from 1940 to present 2” [original data]. Source: Contains modified Copernicus Climate Change Service information (2025) – with major processing by Our World In Data\n\n\n\n\nThis parameter is the accumulated liquid and frozen water, comprising rain and snow, that falls to the Earth’s surface. It is the sum of large-scale precipitation and convective precipitation. Large-scale precipitation is generated by the cloud scheme in the ECMWF Integrated Forecasting System (IFS). The cloud scheme represents the formation and dissipation of clouds and large-scale precipitation due to changes in atmospheric quantities (such as pressure, temperature and moisture) predicted directly by the IFS at spatial scales of the grid box or larger. Convective precipitation is generated by the convection scheme in the IFS, which represents convection at spatial scales smaller than the grid box. This parameter does not include fog, dew or the precipitation that evaporates in the atmosphere before it lands at the surface of the Earth. This parameter is accumulated over a particular time period which depends on the data extracted. For the monthly averaged reanalysis and the monthly averaged ensemble members, the accumulation period is 1 day. For the monthly averaged reanalysis by hour of day, the accumulation period is 1 hour and for the monthly averaged ensemble members by hour of day, the accumulation period is 3 hours. The units of this parameter are depth in metres of water equivalent. It is the depth the water would have if it were spread evenly over the grid box. Care should be taken when comparing model parameters with observations, because observations are often local to a particular point in space and time, rather than representing averages over a model grid box.\n\n\n\n\n\nRetrieved on: 2025-01-07\nRetrieved from: https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-monthly-means?tab=overview\n\n\n\n\nInitially, the dataset is provided with specific coordinates in terms of longitude and latitude. To tailor this data to each country, we use geographical boundaries as defined by the World Bank. The method involves trimming the precipitation dataset to match the exact geographical shape of each country. To correct for potential distortions caused by projecting the Earth’s curved surface onto a flat map, we apply a latitude-based weighting. This step is essential for maintaining accuracy, particularly in high-latitude regions where distortion is more pronounced. The result of this process is a latitude-weighted average precipitation for each nation.\nIt’s important to note, however, that due to the resolution constraints of the Copernicus dataset, this methodology might not be as effective for countries with very small landmasses. In such cases, the process may not yield reliable data.\nThe derived precipitation for each country is calculated based on administrative borders, encompassing all land surface types within these areas. As a result, precipitation over oceans and seas is not included in these averages, keeping the data focused on terrestrial environments.\nGlobal precipitation averages and anomalies, however, are calculated over both land and ocean surfaces.\nThe precipitation anomaly is calculated by comparing the average precipitation of a specific time period (e.g., a particular year or month) to the average surface precipitation of the same period from 1991 to 2020.\nWhen calculating anomalies for each country, the total precipitation of a given year or month is compared to the 1991-2020 average precipitation for that specific country.\nThe reason for using the 1991-2020 period as the reference mean is that it is the standard reference period used by our data source, the Copernicus Climate Change Service. This period is also adopted by the UK Met Office. This approach ensures consistency in identifying climate variations over time."
  },
  {
    "objectID": "data/precipitation/readme.html#csv-structure",
    "href": "data/precipitation/readme.html#csv-structure",
    "title": "Annual precipitation - Data package",
    "section": "",
    "text": "The high level structure of the CSV file is that each row is an observation for an entity (usually a country or region) and a timepoint (usually a year).\nThe first two columns in the CSV file are “Entity” and “Code”. “Entity” is the name of the entity (e.g. “United States”). “Code” is the OWID internal entity code that we use if the entity is a country or region. For normal countries, this is the same as the iso alpha-3 code of the entity (e.g. “USA”) - for non-standard countries like historical countries these are custom codes.\nThe third column is either “Year” or “Day”. If the data is annual, this is “Year” and contains only the year as an integer. If the column is “Day”, the column contains a date string in the form “YYYY-MM-DD”.\nThe final column is the data column, which is the time series that powers the chart. If the CSV data is downloaded using the “full data” option, then the column corresponds to the time series below. If the CSV data is downloaded using the “only selected data visible in the chart” option then the data column is transformed depending on the chart type and thus the association with the time series might not be as straightforward."
  },
  {
    "objectID": "data/precipitation/readme.html#metadata.json-structure",
    "href": "data/precipitation/readme.html#metadata.json-structure",
    "title": "Annual precipitation - Data package",
    "section": "",
    "text": "The .metadata.json file contains metadata about the data package. The “charts” key contains information to recreate the chart, like the title, subtitle etc.. The “columns” key contains information about each of the columns in the csv, like the unit, timespan covered, citation for the data etc.."
  },
  {
    "objectID": "data/precipitation/readme.html#about-the-data",
    "href": "data/precipitation/readme.html#about-the-data",
    "title": "Annual precipitation - Data package",
    "section": "",
    "text": "Our World in Data is almost never the original producer of the data - almost all of the data we use has been compiled by others. If you want to re-use data, it is your responsibility to ensure that you adhere to the sources’ license and to credit them correctly. Please note that a single time series may have more than one source - e.g. when we stich together data from different time periods by different producers or when we calculate per capita metrics using population data from a second source."
  },
  {
    "objectID": "data/precipitation/readme.html#annual-precipitation",
    "href": "data/precipitation/readme.html#annual-precipitation",
    "title": "Annual precipitation - Data package",
    "section": "",
    "text": "Total annual precipitation—rain and snow—calculated as the sum of daily averages, reported as the depth of water falling to Earth’s surface, excluding fog and dew. Last updated: January 7, 2025\nNext update: July 2025\nDate range: 1940–2024\nUnit: millimeters\n\n\n\n\nIf you have limited space (e.g. in data visualizations), you can use this abbreviated in-line citation:\nContains modified Copernicus Climate Change Service information (2025) – with major processing by Our World in Data\n\n\n\nContains modified Copernicus Climate Change Service information (2025) – with major processing by Our World in Data. “Annual precipitation” [dataset]. Contains modified Copernicus Climate Change Service information, “ERA5 monthly averaged data on single levels from 1940 to present 2” [original data]. Source: Contains modified Copernicus Climate Change Service information (2025) – with major processing by Our World In Data\n\n\n\n\nThis parameter is the accumulated liquid and frozen water, comprising rain and snow, that falls to the Earth’s surface. It is the sum of large-scale precipitation and convective precipitation. Large-scale precipitation is generated by the cloud scheme in the ECMWF Integrated Forecasting System (IFS). The cloud scheme represents the formation and dissipation of clouds and large-scale precipitation due to changes in atmospheric quantities (such as pressure, temperature and moisture) predicted directly by the IFS at spatial scales of the grid box or larger. Convective precipitation is generated by the convection scheme in the IFS, which represents convection at spatial scales smaller than the grid box. This parameter does not include fog, dew or the precipitation that evaporates in the atmosphere before it lands at the surface of the Earth. This parameter is accumulated over a particular time period which depends on the data extracted. For the monthly averaged reanalysis and the monthly averaged ensemble members, the accumulation period is 1 day. For the monthly averaged reanalysis by hour of day, the accumulation period is 1 hour and for the monthly averaged ensemble members by hour of day, the accumulation period is 3 hours. The units of this parameter are depth in metres of water equivalent. It is the depth the water would have if it were spread evenly over the grid box. Care should be taken when comparing model parameters with observations, because observations are often local to a particular point in space and time, rather than representing averages over a model grid box.\n\n\n\n\n\nRetrieved on: 2025-01-07\nRetrieved from: https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels-monthly-means?tab=overview\n\n\n\n\nInitially, the dataset is provided with specific coordinates in terms of longitude and latitude. To tailor this data to each country, we use geographical boundaries as defined by the World Bank. The method involves trimming the precipitation dataset to match the exact geographical shape of each country. To correct for potential distortions caused by projecting the Earth’s curved surface onto a flat map, we apply a latitude-based weighting. This step is essential for maintaining accuracy, particularly in high-latitude regions where distortion is more pronounced. The result of this process is a latitude-weighted average precipitation for each nation.\nIt’s important to note, however, that due to the resolution constraints of the Copernicus dataset, this methodology might not be as effective for countries with very small landmasses. In such cases, the process may not yield reliable data.\nThe derived precipitation for each country is calculated based on administrative borders, encompassing all land surface types within these areas. As a result, precipitation over oceans and seas is not included in these averages, keeping the data focused on terrestrial environments.\nGlobal precipitation averages and anomalies, however, are calculated over both land and ocean surfaces.\nThe precipitation anomaly is calculated by comparing the average precipitation of a specific time period (e.g., a particular year or month) to the average surface precipitation of the same period from 1991 to 2020.\nWhen calculating anomalies for each country, the total precipitation of a given year or month is compared to the 1991-2020 average precipitation for that specific country.\nThe reason for using the 1991-2020 period as the reference mean is that it is the standard reference period used by our data source, the Copernicus Climate Change Service. This period is also adopted by the UK Met Office. This approach ensures consistency in identifying climate variations over time."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "100-eda.html",
    "href": "100-eda.html",
    "title": "EDA",
    "section": "",
    "text": "Goals\nThe project shall aim to study the effect of precipitation and temperature on crop yield.\n\n\nData\n\nThe data on crop yield was obtained from the Food and Agriculture Organization of the United Nations, which includes various data on crops and livestock products from across the world. The project shall mainly focus on data for the United Kingdom.\nThe data for precipitation was obtained from Out World in Data, and records the average precipitation for countries on an annual basis.\nThe data for temperature was obtained from the World Bank Group. It contains historic data on the mean surface air temperature.\n\nWe shall mainly be looking at 3 crops: wheat, barley, and rapeseed, which represent the 3 most popular crops grown in the UK(TODO: citation).\n There appears to be a general trend of better crop yield over time. The yield of all 3 crops appears to be highly correlated, suggesting that they have common causes.\n \nWe can see clearly that for each crop the yield is positively correlated with annual precipitation and average temperature."
  },
  {
    "objectID": "analyses/100-eda.html",
    "href": "analyses/100-eda.html",
    "title": "100-eda",
    "section": "",
    "text": "Loading required package: ggplot2\n\n\nLoading required package: data.table\n\n\nLoading required package: here\n\n\nhere() starts at C:/Users/harry/Projects/Imperial/Data_Science/Crop_yield_CW\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()     masks data.table::between()\n✖ dplyr::filter()      masks stats::filter()\n✖ dplyr::first()       masks data.table::first()\n✖ lubridate::hour()    masks data.table::hour()\n✖ lubridate::isoweek() masks data.table::isoweek()\n✖ dplyr::lag()         masks stats::lag()\n✖ dplyr::last()        masks data.table::last()\n✖ lubridate::mday()    masks data.table::mday()\n✖ lubridate::minute()  masks data.table::minute()\n✖ lubridate::month()   masks data.table::month()\n✖ lubridate::quarter() masks data.table::quarter()\n✖ lubridate::second()  masks data.table::second()\n✖ purrr::transpose()   masks data.table::transpose()\n✖ lubridate::wday()    masks data.table::wday()\n✖ lubridate::week()    masks data.table::week()\n✖ lubridate::yday()    masks data.table::yday()\n✖ lubridate::year()    masks data.table::year()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nSaving 7 x 5 in image\n\n\n\n\n\n\n\n\n\n\ncrop_and_precipitation_data &lt;- merge(crop_data, precipitation_data, by=\"Year\")\n\np &lt;- ggplot(crop_and_precipitation_data, \n       aes(x=Annual.precipitation, \n           y=Yield, \n           group=Item, \n           colour=Item)) +\n  geom_point() +\n  labs(x = \"Annual Precipitation (mm)\") +\n  theme_minimal()\n\nggsave(file = file.path(out.dir, '100-eda', 'precipitation_yield.png'), p)\n\nSaving 7 x 5 in image\n\np\n\n\n\n\n\n\n\n\n\nfile &lt;- file.path(data.dir, 'temp', 'observed-annual-average.csv')\ndt &lt;- as.data.table(read.csv(file))\n\ntemp_data &lt;- dt %&gt;%\n  rename(Year = Category,\n         Avg.Temp = Annual.Mean) %&gt;%\n  select(-X5.yr.smooth)\n\n\ncrop_and_temp_data &lt;- merge(crop_data, temp_data, by=\"Year\")\n\np &lt;- ggplot(crop_and_temp_data, \n       aes(x=Avg.Temp, \n           y=Yield, \n           group=Item, \n           colour=Item)) +\n  geom_point() +\n  labs(x = \"Average temperature (Celsius)\") +\n  theme_minimal()\n\nggsave(file = file.path(out.dir, '100-eda', 'temp_yield.png'), p)\n\nSaving 7 x 5 in image\n\np"
  }
]